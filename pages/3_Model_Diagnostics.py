import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import sys
import os

# --- CONFIGURATION ---
st.set_page_config(page_title="Diagnostic Mod√®le", page_icon="ü©∫", layout="wide")

# Ajout du dossier parent au path pour importer journal_utils
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from journal_utils import get_text_data, get_numeric_data
except ImportError:
    st.error("‚ùå Impossible de charger 'journal_utils.py'. Assurez-vous qu'il est √† la racine.")
    st.stop()

# Chemins
MODEL_FILE = "model_xgboost_publisher.pkl"
DATA_FILE = "data/02_real_world_dataset.csv"

# --- TITRE ---
st.title("ü©∫ Diagnostic Complet du Mod√®le (XGBoost + RF)")
st.markdown("---")

# --- 1. CHARGEMENT ET PR√âPARATION ---
@st.cache_data
def load_and_evaluate():
    if not os.path.exists(MODEL_FILE) or not os.path.exists(DATA_FILE):
        return None, None, None, None

    # Chargement
    df = pd.read_csv(DATA_FILE)
    model = joblib.load(MODEL_FILE)

    # Nettoyage (Idem entra√Ænement)
    df['Publisher'] = df['Publisher'].fillna('Unknown')
    df['Titre'] = df['Titre'].fillna('')
    cols_num = ['oa_works', 'oa_cited', 'oa_found', 'cr_has_doi', 'Impact_Ratio']
    for col in cols_num:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # Split (M√™me graine random_state=42 pour reproduire les r√©sultats)
    X = df
    y = df['Est_Predateur']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # Pr√©dictions
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # Probabilit√©s pour le test (pour l'analyse fine)
    probs_test = model.predict_proba(X_test)[:, 1]

    return df, y_train, y_pred_train, y_test, y_pred_test, probs_test

df, y_train, y_pred_train, y_test, y_pred_test, probs_test = load_and_evaluate()

if df is None:
    st.error("Fichiers manquants (Mod√®le ou Data). Lancez le pipeline d'abord.")
    st.stop()

# --- 2. ANALYSE OVERFITTING (Train vs Test) ---
st.header("1. Analyse de la Robustesse (Overfitting)")

col1, col2, col3 = st.columns(3)

acc_train = accuracy_score(y_train, y_pred_train)
acc_test = accuracy_score(y_test, y_pred_test)
gap = acc_train - acc_test

with col1:
    st.metric("üéØ Pr√©cision TRAIN (Apprentissage)", f"{acc_train:.2%}")
    st.caption("Capacit√© du mod√®le √† apprendre par c≈ìur.")

with col2:
    st.metric("üèÜ Pr√©cision TEST (R√©alit√©)", f"{acc_test:.2%}")
    st.caption("Capacit√© du mod√®le √† g√©n√©raliser.")

with col3:
    st.metric("‚ö†Ô∏è √âcart (Gap)", f"{gap:.2%}", delta_color="inverse")
    
    if gap < 0.05:
        st.success("‚úÖ **EXCELLENT** : Pas d'overfitting (< 5%)")
    elif gap < 0.10:
        st.warning("‚ö†Ô∏è **ATTENTION** : L√©ger overfitting (5-10%)")
    else:
        st.error("üö® **DANGER** : Fort overfitting (> 10%)")

# --- 3. MATRICE DE CONFUSION ---
st.header("2. Matrice de Confusion (O√π se trompe-t-il ?)")

col_conf, col_details = st.columns([1, 1])

with col_conf:
    cm = confusion_matrix(y_test, y_pred_test)
    fig_cm, ax = plt.subplots(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=['Fiable (0)', 'Pr√©dateur (1)'],
                yticklabels=['Fiable (0)', 'Pr√©dateur (1)'])
    plt.xlabel('Pr√©dit par IA')
    plt.ylabel('R√©alit√©')
    plt.title('Matrice de Confusion (Test Set)')
    st.pyplot(fig_cm)

with col_details:
    tn, fp, fn, tp = cm.ravel()
    st.write("#### üîç Analyse des Erreurs :")
    
    st.info(f"‚úÖ **Vrais Fiables : {tn}** (Revues honn√™tes bien valid√©es)")
    st.success(f"üïµÔ∏è **Vrais Pr√©dateurs : {tp}** (Arnaques bien bloqu√©es)")
    
    st.warning(f"‚ö†Ô∏è **Fausses Alertes (FP) : {fp}**\nRevues fiables class√©es comme arnaques (Parano√Øa du mod√®le).")
    
    st.error(f"‚ò†Ô∏è **Arnaques Rat√©es (FN) : {fn}**\nLe plus dangereux ! Arnaques pass√©es entre les mailles du filet.")
    
    if fn < 70:
        # st.balloons()  <-- LIGNE SUPPRIM√âE
        st.caption("üèÜ Objectif de s√©curit√© atteint (< 70 rat√©s)")

# --- 4. CORR√âLATIONS ---
st.header("3. Corr√©lations des Donn√©es")
st.markdown("Quelles caract√©ristiques (Features) sont les plus li√©es √† la fraude ?")

# On calcule la corr√©lation sur tout le dataset
corr_cols = ['Est_Predateur', 'oa_works', 'oa_cited', 'oa_found', 'cr_has_doi', 'Impact_Ratio']
corr_matrix = df[corr_cols].corr()

fig_corr, ax = plt.subplots(figsize=(8, 3))
sns.heatmap(corr_matrix[['Est_Predateur']].sort_values(by='Est_Predateur', ascending=False), 
            annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title("Corr√©lation avec la cible 'Est_Predateur'")
st.pyplot(fig_corr)

st.info("""
**Interpr√©tation :**
* Une valeur proche de **1** signifie que si ce chiffre monte, le risque d'arnaque monte.
* Une valeur proche de **-1** signifie que si ce chiffre monte, le risque d'arnaque **baisse** (ex: Impact_Ratio).
""")

# --- 5. RAPPORT D'APPROCHE ---
st.header("4. Architecture Technique")

with st.expander("Voir les d√©tails de l'algorithme utilis√©", expanded=True):
    st.markdown("""
    ### üß† Architecture Hybride "Voting Classifier"
    
    Ce mod√®le n'est pas une simple IA, c'est un **comit√© d'experts** compos√© de deux algorithmes qui votent ensemble :
    
    1.  **XGBoost (Expert Pr√©cision)** üöÄ
        * **R√¥le :** Analyse les motifs complexes et les relations non-lin√©aires.
        * **Sp√©cialit√© :** D√©tecte les signaux faibles dans le texte (Titre + √âditeur).
        * **Configuration :** Profondeur limit√©e (Max Depth=5) pour √©viter l'apprentissage par c≈ìur.
        * **S√©curit√© :** Utilise `scale_pos_weight=1.5` pour punir s√©v√®rement les arnaques rat√©es.
    
    2.  **Random Forest (Expert Stabilit√©)** üå≥
        * **R√¥le :** Assure la robustesse globale en moyennant des centaines d'arbres de d√©cision.
        * **Sp√©cialit√© :** Tr√®s bon pour traiter les m√©triques brutes (Citations, Ratio).
        * **Poids :** Compte pour 1/3 de la d√©cision finale.
    
    ### ‚öôÔ∏è Traitement des Donn√©es (Pipeline)
    * **NLP (Texte) :** TF-IDF sur 6000 mots-cl√©s (1-3 ngrams). Combine le Titre et l'√âditeur.
    * **Stats (Num√©rique) :** Standardisation des citations et du ratio d'impact.
    * **Seuil de D√©cision :** Optimis√© dynamiquement (pas juste 50%) pour maximiser le F1-Score.
    """)