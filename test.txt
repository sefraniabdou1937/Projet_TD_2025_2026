1 - 
"Cette diapositive résume le cœur de notre ingénierie : comment nous transformons la donnée brute en intelligence.

Comme vous le voyez sur ce schéma, notre architecture ne se contente pas de lire des fichiers Excel.
Elle orchestre un traitement parallèle via deux canaux distincts :

    - En haut, le Canal Sémantique (NLP) : Nous traitons le texte — le titre et l'éditeur — via une vectorisation TF-IDF. Cela permet à la machine de comprendre le sens des mots et de repérer des imitations suspectes.


    - En bas, le Canal Statistique (Maths) : Simultanément, nous injectons les métriques de crédibilité (citations, impact) que nous normalisons via un Scaler  pour les rendre comparables.

C'est ici que nous fusionnons ces deux mondes.
Nous créons ainsi un vecteur dense unique qui capture à la fois le contenu et la performance de la revue, 
fournissant à notre IA une vision complète pour sa prise de décision

2- 

Ici, c'est notre module d'analyse sémantique.

Ce pipeline utilise la technique TF-IDF pour transformer le texte brut (Titre et Éditeur) en une empreinte numérique.

En analysant des séquences de 1 à 3 mots, il capture les motifs linguistiques suspects — comme des titres trompeurs ou trop génériques — que l'œil humain pourrait rater.

En parallèle, voici notre canal d'audit bibliométrique.

Ce pipeline extrait les métriques clés — comme les citations ou l'Impact Ratio — et comble automatiquement les données manquantes par des zéros.

Surtout, il applique un StandardScaler pour normaliser les valeurs. C'est crucial : cela ramène des millions de citations et de simples variables binaires sur une échelle commune, garantissant que l'IA ne soit pas biaisée par la grandeur des chiffres.

3- 

Nous arrivons maintenant au cœur décisionnel de notre solution : Le Moteur Hybride.

Contrairement aux approches classiques qui utilisent un seul algorithme, nous avons conçu un système de 'Double Expertise' pour maximiser la sécurité.

1. Notre Premier Expert : Le XGBoost (Le 'Chasseur') C'est notre modèle principal. Nous l'avons configuré très spécifiquement pour la chasse à la fraude :

D'abord, avec un apprentissage très lent (learning_rate=0.02), pour qu'il ne rate aucun détail subtil.

Ensuite, et c'est capital, nous lui avons donné un paramètre de sévérité (scale_pos_weight=1.5). Concrètement, cela signifie qu'il considère qu'un faux négatif (rater une arnaque) est bien plus grave qu'une fausse alerte. Il est donc nativement agressif envers les revues prédatrices.

2. Notre Second Expert : Le Random Forest (Le 'Stabilisateur') Pour éviter que le XGBoost ne devienne trop paranoïaque ou ne fasse du sur-apprentissage, nous l'avons couplé à un Random Forest. Son rôle est de 'calmer le jeu' en apportant une vision statistique plus globale et robuste.

3. Le Verdict : Le Soft Voting Enfin, ces deux modèles votent. Mais ce n'est pas un vote égalitaire : via le VotingClassifier, nous donnons deux fois plus de poids au XGBoost (le spécialiste) qu'au Random Forest.

Le résultat n'est pas une simple décision binaire, mais une Probabilité de Risque pondérée. C'est cette architecture qui nous permet d'atteindre notre taux de détection élevé tout en maintenant une grande stabilité sur les nouvelles données

4-

Voici le moment de vérité : la performance réelle.

Les chiffres sont clairs : nous obtenons 85.8% de précision sur le test, avec un écart minime de 3% par rapport à l'entraînement. Cela prouve que notre modèle est stable et ne fait pas de sur-apprentissage.

Concrètement, regardez la matrice : nous avons réussi à bloquer net 402 revues prédatrices . Les quelques ratés restants (les 92 faux négatifs) seront corrigés progressivement grâce à notre boucle d'auto-apprentissage

5-

Pour conclure sur la technique : nous avons donc un moteur hybride validé, capable de distinguer le vrai du faux avec 85.8% de fiabilité.

Mais soyons honnêtes : en Intelligence Artificielle, un modèle statique est un modèle mort. Pour dépasser les 90% et viser l'excellence, il nous manque une seule ressource critique : plus de données hétérogènes.


