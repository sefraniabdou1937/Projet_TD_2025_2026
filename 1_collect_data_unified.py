import pandas as pd
import requests
import os
import io
import random

# --- CONFIGURATION ---
OUTPUT_FILE = "data/01_journal_names.csv"
DOAJ_CSV_URL = "https://doaj.org/csv"  # Le lien magique pour tout avoir d'un coup
URL_BAD_JOURNALS = "https://raw.githubusercontent.com/stop-predatory-journals/stop-predatory-journals.github.io/master/_data/journals.csv"
URL_BAD_HIJACKED = "https://raw.githubusercontent.com/predatory-journals/hijacked-journals/main/hijacked-journals.csv"
URL_BAD_PUBLISHERS = "https://raw.githubusercontent.com/stop-predatory-journals/stop-predatory-journals.github.io/master/_data/publishers.csv"

if not os.path.exists('data'):
    os.makedirs('data')

print("--- üìë COLLECTE UNIFI√âE : LE SCRIPT ULTIME ---")

# =========================================================
# 1. R√âCUP√âRATION DES PR√âDATEURS (SOURCES GITHUB)
# =========================================================
def get_predators():
    print("\n1Ô∏è‚É£  R√©cup√©ration des Revues Pr√©datrices...")
    bad_names = set()

    # Source A : Liste classique
    try:
        print("   ‚Ü≥ Stop-Predatory-Journals...")
        df = pd.read_csv(URL_BAD_JOURNALS)
        bad_names.update(df['name'].dropna().unique().tolist())
    except Exception as e:
        print(f"     ‚ùå Erreur : {e}")

    # Source B : Revues D√©tourn√©es
    try:
        print("   ‚Ü≥ Hijacked Journals...")
        try:
            df = pd.read_csv(URL_BAD_HIJACKED, on_bad_lines='skip')
        except:
            df = pd.read_csv(URL_BAD_HIJACKED, error_bad_lines=False)
        
        # Trouver la colonne titre
        col = next((c for c in df.columns if 'Title' in c or 'Journal' in c), None)
        if col:
            bad_names.update(df[col].dropna().unique().tolist())
    except:
        pass

    # Source C : √âditeurs douteux
    try:
        print("   ‚Ü≥ √âditeurs Pr√©dateurs...")
        df = pd.read_csv(URL_BAD_PUBLISHERS)
        bad_names.update(df['name'].dropna().unique().tolist())
    except:
        pass

    print(f"   üî• Total Arnaques trouv√©es : {len(bad_names)}")
    return list(bad_names)

# =========================================================
# 2. R√âCUP√âRATION DES FIABLES (DUMP CSV DOAJ)
# =========================================================
def get_legit_journals(target_count):
    print(f"\n2Ô∏è‚É£  R√©cup√©ration des Revues Fiables (Cible : ~{target_count})...")
    print("   ‚è≥ T√©l√©chargement du Dump DOAJ (20-30MB)...")
    
    try:
        # On t√©l√©charge le gros fichier d'un coup
        response = requests.get(DOAJ_CSV_URL, timeout=60)
        response.raise_for_status()
        
        # On le lit en m√©moire
        csv_content = io.StringIO(response.content.decode('utf-8'))
        df_doaj = pd.read_csv(csv_content)
        
        # On extrait les titres
        if 'Journal title' in df_doaj.columns:
            all_titles = df_doaj['Journal title'].dropna().unique().tolist()
            print(f"   üìö Base DOAJ compl√®te charg√©e : {len(all_titles)} revues.")
            
            # On en prend juste ce qu'il faut pour √©quilibrer (+ une petite marge)
            count_to_take = min(target_count, len(all_titles))
            selected = random.sample(all_titles, count_to_take)
            print(f"   ‚ú® S√©lection al√©atoire de {len(selected)} revues fiables.")
            return selected
        else:
            print("   ‚ùå Erreur structure CSV DOAJ.")
            return []
            
    except Exception as e:
        print(f"   ‚ùå Erreur t√©l√©chargement DOAJ : {e}")
        return []

# =========================================================
# 3. FUSION ET SAUVEGARDE
# =========================================================
def main():
    # A. R√©cup√©rer les m√©chants
    bad_list = get_predators()
    
    if not bad_list:
        print("‚ùå Arr√™t critique : Impossible de trouver des pr√©dateurs.")
        return

    # B. R√©cup√©rer les gentils (On vise le m√™me nombre + 500 pour √©quilibrer)
    target_legit = len(bad_list) + 500
    good_list = get_legit_journals(target_legit)

    # C. Cr√©ation du DataFrame
    print("\n3Ô∏è‚É£  Fusion et Nettoyage...")
    
    data = []
    for name in bad_list:
        data.append({'Titre': name, 'Est_Predateur': 1})
    
    for name in good_list:
        data.append({'Titre': name, 'Est_Predateur': 0})
        
    df = pd.DataFrame(data)
    
    # D. Priorit√© aux m√©chants en cas de doublon (S√©curit√©)
    # On trie par Est_Predateur d√©croissant (1 en premier), puis on supprime les doublons de Titre
    df = df.sort_values('Est_Predateur', ascending=False)
    df = df.drop_duplicates(subset=['Titre'], keep='first')
    
    # E. M√©lange final
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # F. Sauvegarde
    df.to_csv(OUTPUT_FILE, index=False)
    
    print(f"\n‚úÖ SUCCESS : Fichier g√©n√©r√© '{OUTPUT_FILE}'")
    print("üìä Bilan du Dataset :")
    print(f"   üî¥ Arnaques : {len(df[df['Est_Predateur']==1])}")
    print(f"   üü¢ Fiables  : {len(df[df['Est_Predateur']==0])}")
    print(f"   ‚àë  TOTAL    : {len(df)}")

if __name__ == "__main__":
    main()